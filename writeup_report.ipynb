{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Files Submitted & Code Quality\n",
    "\n",
    "## 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model_yaml_string.p (pickle file) containing a trained convolution neural network \n",
    "* my_model_weights.h5 the trained weights for the neural network\n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "## 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model_yaml_string.p my_model_weights.h5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "# Model Architecture and Training Strategy\n",
    "\n",
    "## 1. An appropriate model architecture has been employed\n",
    "\n",
    "My model is inspired from the model I used for the Traffic Sign Classification project.\n",
    "The model structure is very similar to the first layers (stem) of Google's newer Inception neural network. Google's model is called Inception v-4 and the full details are in the following arXiv paper:\n",
    "https://arxiv.org/abs/1602.07261\n",
    "\n",
    "My model consists of a convolution neural network with filter sizes and depths between 16 and 64 (model.py lines 260-300).\n",
    "\n",
    "Google model borrows some ideas from ResNet or SqueezeNet (https://arxiv.org/abs/1602.07360) : a 1x1 convolution neural branch shortcuts a sequence of convolution neural layers before merging again (keras variables 'left_branch' and 'right_branch').\n",
    "\n",
    "The model uses ELU activations as described in this paper (https://arxiv.org/abs/1511.07289) for faster learning compared to RELU activations.\n",
    "\n",
    "Also the training image is normalized in the model using a Keras lambda layer and cropped in a cropping layer to remove the sky and the front of the car which are irrelevant for the drive. \n",
    "\n",
    "The model is also using Batch Normalization (https://arxiv.org/abs/1502.03167) in order to accelerate training.\n",
    "\n",
    "\n",
    "<img src=\"model.png\" alt=\"Model\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model contains one Dropout layer in order to reduce overfitting (model.py lines 294). \n",
    "\n",
    "During the model training we made sure that the training loss as well as the validation loss kept decreasing. When the validation loss increases and the training loss starting to increase, it is a sign of overfitting. I did not observe that during training.\n",
    "A healthy sign was that the validation loss was fairly close to the training loss.\n",
    "\n",
    "Finally, I left the model driving the car autonomously over an hour and the car stayed continuously on track.\n",
    "\n",
    "## 3. Model parameter tuning\n",
    "\n",
    "The model is trained on an adam optimizer with a mean squared error loss, and the learning rate left to default values (model.py line 302).\n",
    "\n",
    "The model was trained on 20 EPOCHS.\n",
    "\n",
    "I used a fairly low number of validation examples compared to the training size (10%).\n",
    "This is because of a smaller number of training images than in the Udacity dataset or in my Traffic Sign Classification dataset.\n",
    "\n",
    "## 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of center camera feed, left and right camera feed. I did not perform any recovery manoeuvers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Architecture and Training Strategy\n",
    "\n",
    "## 1. Solution Design Approach\n",
    "\n",
    "I decided to derive my model from a recent neural network achitecture and choose the Google Inception-v4 model as a source of inspiration because it has been very successful for image classification tasks and more lightweight than older architectures like AlexNet.\n",
    "\n",
    "As I stated in the previous section, I have never seen any numerical clues that the model was overfitting at any point in time in the design process.\n",
    "\n",
    "I had 3 majors iterations in the design process until I was able to have the vehicle driving autonomously around the track without leaving the road.\n",
    "\n",
    "\n",
    "### Robustness improvement over the drive (a novel idea?)\n",
    "Having observed that my training dataset is quiet low compared to the dataset provided by Udacity, I was interested in finding a way to improve the robustness of the neural network in a minimal way.\n",
    "\n",
    "A simple idea is to imagine that the road is a potential field on which the car navigates. This concept is well illustrated on this student video : https://www.youtube.com/watch?v=JT8w94n1kWw\n",
    "\n",
    "In order to maintain the car in the center of the road we need to make sure that the potential field sharply increases when the vehicle is closer to the sides of the road or its orientation is not towards the center of the road.\n",
    "With our dataset, the easiest way to artificially increase this field gradient is to increase the steering values in the training dataset by muliplying it by a constant factor (or a gain as called in Control Theory).\n",
    "\n",
    "By appying a gain to the steering dataset the vehicle steers more steering more agressively when approaching dangerously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this fantastic project, I have learnt how to train a Neural Network to drive a car.\n",
    "The project was incredibly fun.\n",
    "After having used a Neural Network for classification, this project uses a Neural net for a regression task.\n",
    "Both tasks are Supervised Learning tasks and I am hoping to experiment with Unsupervised Learning tasks for training an agent in the future."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
